# ğŸª™ Cryptocurrency Price Prediction MLOps Pipeline ğŸš€

A project demonstrating a basic MLOps pipeline for predicting short-term cryptocurrency price movements (specifically, whether the next day's closing price will be higher than the current day's) using historical data from the public CoinGecko API.

**âš ï¸ Disclaimer:** This is a simplified educational example focusing on the MLOps pipeline structure. The prediction model (Logistic Regression with basic features) is not optimized for real-world trading and its performance is low (see `models/training_metrics.json`). Advanced MLOps features like robust monitoring, automated retraining, advanced model validation (CV/HPT), and cloud deployment are not fully implemented.

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/                # ğŸ“Š Data files (generated by pipeline)
â”‚   â”œâ”€â”€ raw/             #   -> Raw data fetched from API
â”‚   â”œâ”€â”€ processed/       #   -> Intermediate processed data
â”‚   â””â”€â”€ features/        #   -> Engineered features for training/prediction
â”œâ”€â”€ models/              # ğŸ¤– Model artifacts (generated by pipeline)
â”‚   â”œâ”€â”€ logistic_regression_model.joblib #   -> Trained model
â”‚   â”œâ”€â”€ minmax_scaler.joblib           #   -> Scaler used for features
â”‚   â””â”€â”€ training_metrics.json        #   -> Evaluation metrics from training
â”œâ”€â”€ notebooks/           # ğŸ““ Jupyter notebooks for exploration (optional)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline/        # ğŸ› ï¸ Core pipeline scripts
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â””â”€â”€ main.py        #   -> Orchestrates pipeline execution
â”‚   â”œâ”€â”€ api/             # ğŸ“¡ FastAPI application
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py        #   -> API endpoints (loads model, serves predictions)
â”‚   â”‚   â””â”€â”€ models.py      #   -> Pydantic models for API input/output
â”‚   â””â”€â”€ monitoring/      # ğŸ‘€ Monitoring-related scripts (placeholders)
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ tests/               # âœ… Unit and integration tests (placeholders)
â”œâ”€â”€ .gitignore           # ğŸš« Git ignore file
â”œâ”€â”€ Dockerfile           # ğŸ³ Docker configuration for API deployment
â”œâ”€â”€ requirements.txt     # ğŸ“„ Project dependencies
â”œâ”€â”€ README.md            # ğŸ“– This file
â””â”€â”€ technical_report.md  # ğŸ“ Detailed technical documentation (template)
```

## âš™ï¸ Setup

1.  **Clone the repository:**
    ```bash
    # Replace with your actual repository link after creating it
    git clone https://github.com/JAdamhub/MLOps-Exam-Submission.git
    cd MLOps-Exam-Submission
    ```
2.  **Create and activate a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Note: If you encounter NumPy version issues, ensure you have `numpy<2.0` in `requirements.txt` as specified.*

## â–¶ï¸ Usage

### 1. Run the Full Data Pipeline:

This command fetches data from CoinGecko, preprocesses it, engineers features, and trains the model, saving artifacts in `data/` and `models/`.

```bash
python src/pipeline/main.py
```

### 2. Run the API Locally (using Uvicorn):

Starts the FastAPI server on `http://localhost:8000`.

```bash
# Make sure you are in the project root directory
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

### 3. Build and Run the API with Docker:

Requires Docker Desktop to be installed and running.

```bash
# Build the Docker image
docker build -t crypto-predictor:latest .

# Run the Docker container
# Use -d to run in detached mode (background)
docker run -d -p 8000:8000 --name crypto-api crypto-predictor:latest
```

To stop the container: `docker stop crypto-api` ğŸ›‘
To remove the container: `docker rm crypto-api` ğŸ—‘ï¸

## ğŸ§ª Testing the API

Once the API is running (either locally with Uvicorn or via Docker), you can test the prediction endpoint:

1.  **Swagger UI:** Open `http://localhost:8000/docs` ğŸ“„ in your browser for an interactive interface.
2.  **cURL:** Use a command-line tool like `curl` ğŸ’».

**Example `curl` command:**

```bash
curl -X 'POST' \
  'http://localhost:8000/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{ 
    "price": 0.5, 
    "market_cap": 0.6, 
    "total_volume": 0.4, 
    "price_lag_1": 0.49, 
    "price_lag_3": 0.48, 
    "price_lag_7": 0.45, 
    "price_sma_7": 0.48, 
    "price_sma_30": 0.46, 
    "price_volatility_14": 0.05, 
    "day_of_week": 3, 
    "month": 10, 
    "year": 2023 
  }'
```

**Getting Sample Feature Data:**

To get realistic input values for the JSON payload above:

1.  Run the pipeline (`python src/pipeline/main.py`).
2.  Open the generated file: `data/features/bitcoin_usd_365d_features.csv`.
3.  Pick any row.
4.  Copy the values for all columns **except** `timestamp` and `target_price_up`.
5.  Use these values in the JSON payload for your API request.

**API Response:**
The API will return a JSON like:
```json
{
  "prediction": 1,  // 1 = Price predicted to go up ğŸ“ˆ, 0 = Price predicted to go down/stay same ğŸ“‰
  "probability": 0.65 // Model's probability estimate for class 1 (price up)
}
```

## ğŸ”© Pipeline Details

*   **Data Source:** CoinGecko API (`/coins/{id}/market_chart` endpoint) ğŸ¦.
*   **Preprocessing:** Forward/backward fill for missing values, `MinMaxScaler` for numerical features ğŸ§¼.
*   **Features:** Lagged prices, Simple Moving Averages (SMA), Rolling Standard Deviation (Volatility), Day of Week, Month, Year ğŸ“Š.
*   **Model:** `LogisticRegression` (from scikit-learn) ğŸ§ .
*   **Target:** Binary classification - Predict if `price` tomorrow > `price` today (Up=1 / Down=0) ğŸ¯.

## ğŸ“ˆ Monitoring

Currently, only basic Python logging is implemented. A full monitoring solution (e.g., tracking metrics over time, data drift detection, alerts) is **not implemented** but would be a crucial addition for a production system. ğŸš§

## ğŸ–¥ï¸ Frontend Link

No frontend component (e.g., Streamlit, GitHub Pages) was developed for this project. âŒ
